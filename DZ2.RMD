---
title: "Кононова ПМИ 3-1"
output:

  html_document:

    df_print: paged

  html_notebook: default

  pdf_document: default

  word_document: default
---
*Модели*: наивный байесовский классификатор, kNN (метод k ближайших соседей).   

*Данные*: сгенерированные.   



Нам понадобится несколько пакетов для работы с перечисленными методами классификации.  



```{r, message = FALSE, warning = F}
library('mlbench')

library('car')

library('class')        # функция knn()

library('e1071')        # функция naiveBayes()

library('MASS')         # функция mvrnorm()



# ядро

my.seed <- 12345

```

### Домашнее задание по примеру 3 из лекции: классы линейно разделимы  



Пример 3 из лекции.  

- $n = `r n`$, доля обучающей выборки: `r train.percent * 100`%  

- класс $Y=0$: $X \sim N((23, 49), \begin{pmatrix}

  3.5^2 & 0 \\

  0 & 3.4^2 \end{pmatrix})$   

- класс $Y=1$: $X \sim N((15, 51), \begin{pmatrix}

  2^2 & 0 \\

  0 & 2.5^2 \end{pmatrix})$  





```{r}

# Генерируем данные ------------------------------------------------------------



# Данные домашнего задания .............................................................


n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# x-ы -- двумерные нормальные случайные величины
set.seed(my.seed)
class.0 <- mvrnorm(45, mu = c(13, 24), 
                   Sigma = matrix(c(20.25, 0, 0, 324), 2, 2, byrow = T))

set.seed(my.seed + 1)
class.1 <- mvrnorm(55, mu = c(13, 14), 
                   Sigma = matrix(c(6.25, 0, 0, 625), 2, 2, byrow = T))

# записываем x-ы в единые векторы (объединяем классы 0 и 1)
x1 <- c(class.0[, 1], class.1[, 1])
x2 <- c(class.0[, 2], class.1[, 2])

# фактические классы Y
y <- c(rep(0, nrow(class.0)), rep(1, nrow(class.1)))





# Конец данных домашнего задания .......................................................





# Отбираем наблюдения в обучающую выборку --------------------------------------

set.seed(my.seed)

inTrain <- sample(seq_along(x1), train.percent*n)

x1.train <- x1[inTrain]

x2.train <- x2[inTrain]

x1.test <- x1[-inTrain]

x2.test <- x2[-inTrain]



# используем истинные правила, чтобы присвоить фактические классы

y.train <- y[inTrain]

y.test <- y[-inTrain]



# фрейм с обучающей выборкой

df.train.1 <- data.frame(x1 = x1.train, x2 = x2.train, y = y.train)

# фрейм с тестовой выборкой

df.test.1 <- data.frame(x1 = x1.test, x2 = x2.test)

```



Нарисуем обучающую выборку на графике. 


```{r, fig.height = 5, fig.width = 5}

# Рисуем обучающую выборку графике ---------------------------------------------




# цвета для графиков

cls <- c('blue', 'orange')

cls.t <- c(rgb(0, 0, 1, alpha = 0.5), rgb(1,0.5,0, alpha = 0.5))

# график истинных классов
plot(df.train.1$x1, df.train.1$x2,
     pch = 21, bg = cls.t[df.train.1[, 'y'] + 1], 
     col = cls.t[df.train.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Обучающая выборка, факт')
```



Обучим модель **наивного байесовского классификатора** и оценим её точность (верность) на обучающей выборке. Поскольку объясняющие переменные для классов сгенерированы как двумерные нормальные распределения и сами классы не перекрываются, следует ожидать, что эта модель окажется точной.   



```{r, fig.height = 5, fig.width = 5}

# Байесовский классификатор ----------------------------------------------------

#  наивный байес: непрерывные объясняющие переменные



# строим модель

nb <- naiveBayes(y ~ ., data = df.train.1)

# получаем модельные значения на обучающей выборке как классы

y.nb.train <- ifelse(predict(nb, df.train.1[, -3], 

                             type = "raw")[, 2] > 0.5, 1, 0)



# график истинных классов

plot(df.train.1$x1, df.train.1$x2,
     
     pch = 21, bg = cls.t[df.train.1[, 'y'] + 1],
     
     col = cls.t[df.train.1[, 'y'] + 1],
     
     xlab = 'X1', ylab = 'Y1',
     
     main = 'Обучающая выборка, модель naiveBayes')

# точки наблюдений, предсказанных по модели

points(df.train.1$x1, df.train.1$x2, 

       pch = 21, bg = cls.t[y.nb.train + 1], 

       col = cls.t[y.nb.train + 1])



# матрица неточностей на обучающей выборке

tbl <- table(y.train, y.nb.train)

tbl



# точность, или верность (Accuracy)

Acc <- sum(diag(tbl)) / sum(tbl)

Acc

```



Так и есть. Наивный байесовский метод достаточно точно разделяет классы на обучающей выборке.   

Сделаем прогноз классов Y на тестовую выборку и оценим точность модели.   



```{r}

# прогноз на тестовую выборку

y.nb.test <- ifelse(predict(nb, df.test.1, type = "raw")[, 2] > 0.5, 1, 0)



# матрица неточностей на тестовой выборке

tbl <- table(y.test, y.nb.test)

tbl



# точность, или верность (Accuracy)

Acc <- sum(diag(tbl)) / sum(tbl)

Acc

```



Построим модель **kNN**. 



```{r, fig.height = 5, fig.width = 5}

# Метод kNN --------------------------------------------------------------------

#  k = 3



# строим модель и делаем прогноз

y.knn.train <- knn(train = scale(df.train.1[, -3]), 

                   test = scale(df.train.1[, -3]),

                   cl = df.train.1$y, k = 3)



# график истинных классов

plot(df.grid.1$x1, df.grid.1$x2, 

     pch = '·', col = cls[df.grid.1[, 'y'] + 1],

     xlab = 'X1', ylab = 'Y1',

     main = 'Обучающая выборка, модель kNN')

# точки наблюдений, предсказанных по модели

points(df.train.1$x1, df.train.1$x2, 

       pch = 21, bg = cls.t[as.numeric(y.knn.train)], 

       col = cls.t[as.numeric(y.knn.train)])



# матрица неточностей на обучающей выборке

tbl <- table(y.train, y.knn.train)

tbl



# точность (Accuracy)

Acc <- sum(diag(tbl)) / sum(tbl)

Acc



```



Точность на обучающей выборке чуть лучше, чем при использовании наивного байесовского метода.   

Оценка точности на тестовой выборке аналогична предыдущему методу.   



```{r}

# прогноз на тестовую выборку

y.knn.test <- knn(train = scale(df.train.1[, -3]), 

                 test = scale(df.test.1[, -3]),

                 cl = df.train.1$y, k = 3)



# матрица неточностей на тестовой выборке

tbl <- table(y.test, y.knn.test)

tbl



# точность (Accuracy)

Acc <- sum(diag(tbl)) / sum(tbl)

Acc

```

Рассчитаем для этой модели характеристики качества и ошибки из лекции: 
TPR, 
SPC, 
PPV, 
NPV, 
FNR, 
FPR, 
FDR, 
MCC.

```{r}
TPR <- tbl[2,2]/sum(tbl[2,])
TPR
SPC <- tbl[1,1]/sum(tbl[1,])
SPC
PPV <- tbl[2,2]/sum(tbl[,2])
PPV
NPV <- tbl[1,1]/sum(tbl[,1])
NPV
TPR <- 1 - TPR
TPR
FPR <- 1 - SPC
FPR
FDR <- 1 - PPV
FDR
MCC <- (sum(diag(tbl))-sum(tbl[1,2], tbl[2,1]))/(sum(tbl[,2])*sum(tbl[2,])*sum(tbl[1,])*sum(tbl[,1]))^(1/2)
MCC

```

